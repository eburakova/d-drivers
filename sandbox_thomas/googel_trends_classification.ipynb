{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for labeling Articles with ranking of related google searches (extracted from google trends)\n",
    "\n",
    "1. Load Data\n",
    "2. Labeling Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 22:41:22.688070: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proprocessing (one time job): Concatenate \"wallbox laden\" and \"Solargenerator\" with other file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read original data with missing rows\n",
    "# df_labels_orig = pd.read_csv('../data/related_queries_orig.csv')\n",
    "# df_labels_orig.drop(['Unnamed: 0'], axis=1, inplace=True)    # file contains unnecessary column\n",
    "\n",
    "# # Read data for \"Wallbox/Laden\" and \"Solargenerator\" \n",
    "# df_wall = pd.read_csv('../data/relatedQueries_Wallbox-Laden.csv')\n",
    "# df_wall['classification_product'] = 'Wallbox/Laden'  # the google search term was \"Wallbox Laden\" and hast to be changed to \"Wallbox/Laden\" enable joining with real classification_product\n",
    "# df_sol = pd.read_csv('../data/relatedQueries_Solargenerator.csv')\n",
    "# df_sol['classification_product'] = 'Solargenerator' \n",
    "\n",
    "# # concatenate all data and export it as CSV\n",
    "# df_labels_new = pd.concat([df_labels_orig, df_wall, df_sol], axis=0).reset_index(drop=True)\n",
    "# df_labels_new.to_csv('../data/related_queries.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data for labeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_features = '../data/data_features.csv'\n",
    "file_path_labels = '../data/related_queries.csv'\n",
    "\n",
    "df = pd.read_csv(file_path_features)\n",
    "df_labels = pd.read_csv(file_path_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enrich page_ids with google score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 22:41:35.891100: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-15 22:41:35.891135: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFXLMRobertaForSequenceClassification were initialized from the model checkpoint at joeddav/xlm-roberta-large-xnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6815, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "page_id                   0\n",
       "classification_product    0\n",
       "abstract                  7\n",
       "meta_description          0\n",
       "meta_title                0\n",
       "text_to_classify          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare dataset\n",
    "relevant_columns = ['page_id', 'classification_product', 'abstract', 'meta_description', 'meta_title' ]\n",
    "df_gscore = df[relevant_columns].copy()\n",
    "df_gscore['text_to_classify'] = df_gscore['abstract'].fillna('') + ' ' + df_gscore['meta_description'].fillna('') + ' ' + df_gscore['meta_title'].fillna('')\n",
    "\n",
    "\n",
    "display(df_gscore.shape)\n",
    "display(df_gscore.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function get_predictions_score\n",
    "def get_predictions_score(prediction):\n",
    "    pred_labels = prediction['labels']\n",
    "    pred_scores = prediction['scores']\n",
    "    \n",
    "    # Find the index of the label with the highest probability\n",
    "    max_index = pred_scores.index(max(pred_scores))\n",
    "    \n",
    "    # Extract the label and its corresponding probability\n",
    "    max_label = pred_labels[max_index]\n",
    "    max_probability = pred_scores[max_index]\n",
    "    \n",
    "    return max_label, max_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trends_classify(filter, testrun=False, df_labels=df_labels, df_gscore=df_gscore, classifier=classifier):\n",
    "    iter = filter\n",
    "\n",
    "    df_labels_per_category = df_labels[df_labels['classification_product'] == iter]\n",
    "    candidate_labels = df_labels_per_category['query'].astype(str).tolist()\n",
    "\n",
    "    df_gscore_iter = df_gscore[df_gscore['classification_product'] == iter]\n",
    "\n",
    "    if testrun:\n",
    "        df_gscore_iter = df_gscore_iter.iloc[0:2]\n",
    "\n",
    "    tqdm.pandas(desc=f\"Googel search related keyword classification for {iter}\")\n",
    "    df_gscore_iter['predicted_query_label'], df_gscore_iter['predicted_probability'] = zip(*df_gscore_iter['text_to_classify'].progress_apply(lambda x: get_predictions_score(classifier(x, candidate_labels))))\n",
    "\n",
    "    return df_gscore_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_product = df.classification_product.unique().tolist()\n",
    "df_gscore_out = pd.DataFrame(columns=relevant_columns + ['text_to_classify', 'predicted_query_label', 'predicted_probability'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Googel search related keyword classification for E-Auto: 100%|██████████| 2/2 [00:31<00:00, 15.68s/it]\n",
      "Googel search related keyword classification for Auto: 100%|██████████| 2/2 [00:29<00:00, 14.55s/it]\n",
      "Googel search related keyword classification for Zubehör: 100%|██████████| 2/2 [00:09<00:00,  4.83s/it]\n",
      "Googel search related keyword classification for Motorrad: 100%|██████████| 2/2 [00:30<00:00, 15.20s/it]\n",
      "Googel search related keyword classification for Energie: 100%|██████████| 2/2 [00:24<00:00, 12.14s/it]\n",
      "Googel search related keyword classification for Verkehr: 100%|██████████| 2/2 [00:06<00:00,  3.45s/it]\n",
      "Googel search related keyword classification for Wallbox/Laden: 100%|██████████| 2/2 [00:31<00:00, 15.75s/it]\n",
      "Googel search related keyword classification for Solaranlagen: 100%|██████████| 2/2 [00:09<00:00,  4.85s/it]\n",
      "Googel search related keyword classification for E-Bike: 100%|██████████| 2/2 [00:30<00:00, 15.31s/it]\n",
      "Googel search related keyword classification for Fahrrad: 100%|██████████| 2/2 [00:29<00:00, 14.84s/it]\n",
      "Googel search related keyword classification for E-Scooter: 100%|██████████| 2/2 [00:31<00:00, 15.95s/it]\n",
      "Googel search related keyword classification for Solarspeicher: 100%|██████████| 2/2 [00:28<00:00, 14.23s/it]\n",
      "Googel search related keyword classification for Balkonkraftwerk: 100%|██████████| 2/2 [00:29<00:00, 14.85s/it]\n",
      "Googel search related keyword classification for Solargenerator: 100%|██████████| 2/2 [00:12<00:00,  6.09s/it]\n",
      "Googel search related keyword classification for THG: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]\n",
      "Googel search related keyword classification for Wärmepumpe: 100%|██████████| 2/2 [00:29<00:00, 14.84s/it]\n",
      "Googel search related keyword classification for Versicherung: 100%|██████████| 2/2 [00:30<00:00, 15.19s/it]\n",
      "100%|██████████| 17/17 [06:38<00:00, 23.45s/it]\n"
     ]
    }
   ],
   "source": [
    "for cp in tqdm(class_product):\n",
    "    df_gscore_classified = trends_classify(cp, testrun=True)\n",
    "    df_gscore_out = pd.concat([df_gscore_out, df_gscore_classified], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labels['predicted_query_label'] = df_labels['query']\n",
    "df_labels = df_labels.rename(columns={'query': 'predicted_query_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gscore_new = df_gscore_out.merge(df_labels, on=['classification_product', 'predicted_query_label'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 3 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   predicted_query_label   351 non-null    object\n",
      " 1   value                   351 non-null    int64 \n",
      " 2   classification_product  351 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 8.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(34, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(34, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_labels.info())\n",
    "display(df_gscore_out.shape)\n",
    "display(df_gscore_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gscore_new = df_gscore_new.rename(columns={'value': 'query_score'})\n",
    "# df_gscore_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gscore_new.to_csv('../data/google_trends/data_trends_classified.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d-drivers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
