{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "def export_model_sample(\n",
    "    project: str,\n",
    "    model_id: str,\n",
    "    gcs_destination_output_uri_prefix: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    timeout: int = 300,\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    output_config = {\n",
    "        \"artifact_destination\": {\n",
    "            \"output_uri_prefix\": gcs_destination_output_uri_prefix\n",
    "        },\n",
    "        # For information about export formats: https://cloud.google.com/ai-platform-unified/docs/export/export-edge-model#aiplatform_export_model_sample-drest\n",
    "        \"export_format_id\": \"tf-saved-model\",\n",
    "    }\n",
    "    name = client.model_path(project=project, location=location, model=model_id)\n",
    "    response = client.export_model(name=name, output_config=output_config)\n",
    "    print(\"Long running operation:\", response.operation.name)\n",
    "    print(\"output_info:\", response.metadata.output_info)\n",
    "    export_model_response = response.result(timeout=timeout)\n",
    "    print(\"export_model_response:\", export_model_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai endpoints export \\\n",
    "  --region=europe-north1 \\\n",
    "  --model=transformations-all-features-scaled-target.json\\\n",
    "  --output-uri=gs://cloud-ai-platform-63a5e957-921e-4e42-9b23-8c38a4a83e6a/transformations-all-features-scaled-target.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai endpoints export --region=<REGION> --model=<MODEL_NAME> --output-uri=https://storage.cloud.google.com/cloud-ai-platform-63a5e957-921e-4e42-9b23-8c38a4a83e6a/transformations-all-features-scaled-target.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new TensorFlow graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Load the model\n",
    "    loaded_model = tf.saved_model.load('./tf-saved-model/2024-04-12T07:29:42.410616Z/lower_bound/001')\n",
    "\n",
    "# Use the loaded model for inference\n",
    "# For example:\n",
    "# predictions = loaded_model(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = loaded_model(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
